{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('marksheet.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Urdu</th>\n",
       "      <th>Math</th>\n",
       "      <th>Science</th>\n",
       "      <th>Social Studies</th>\n",
       "      <th>total</th>\n",
       "      <th>percent</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>94</td>\n",
       "      <td>40</td>\n",
       "      <td>85</td>\n",
       "      <td>70</td>\n",
       "      <td>334</td>\n",
       "      <td>66.8</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>89</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>312</td>\n",
       "      <td>62.4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>94</td>\n",
       "      <td>357</td>\n",
       "      <td>71.4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>86</td>\n",
       "      <td>64</td>\n",
       "      <td>322</td>\n",
       "      <td>64.4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>96</td>\n",
       "      <td>94</td>\n",
       "      <td>65</td>\n",
       "      <td>382</td>\n",
       "      <td>76.4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   English  Urdu  Math  Science  Social Studies  total  percent grade\n",
       "0       45    94    40       85              70    334     66.8     B\n",
       "1       42    96    89       41              44    312     62.4     B\n",
       "2       43    54    83       83              94    357     71.4     A\n",
       "3       49    66    57       86              64    322     64.4     B\n",
       "4       72    55    96       94              65    382     76.4     A"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['English', 'Urdu', 'Math', 'Science', 'Social Studies', 'total']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['percent']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 6)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 1)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(6, activation = \"relu\", input_shape = (6,)))\n",
    "model.add(Dense(6, activation = \"relu\"))\n",
    "model.add(Dense(6, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer = \"rmsprop\", loss = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70 samples\n",
      "Epoch 1/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 18.1536\n",
      "Epoch 2/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 17.8210\n",
      "Epoch 3/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 17.3211\n",
      "Epoch 4/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 17.1193\n",
      "Epoch 5/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 17.1014\n",
      "Epoch 6/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 17.1644\n",
      "Epoch 7/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 16.3672\n",
      "Epoch 8/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 16.0597\n",
      "Epoch 9/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 15.9460\n",
      "Epoch 10/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 15.8405\n",
      "Epoch 11/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 15.3816\n",
      "Epoch 12/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 15.6164\n",
      "Epoch 13/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 15.1349\n",
      "Epoch 14/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 14.9421\n",
      "Epoch 15/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 14.6158\n",
      "Epoch 16/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 14.4071\n",
      "Epoch 17/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 14.3042\n",
      "Epoch 18/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 14.2876\n",
      "Epoch 19/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 13.9575\n",
      "Epoch 20/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 13.6005\n",
      "Epoch 21/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 13.4647\n",
      "Epoch 22/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 13.2251\n",
      "Epoch 23/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 12.9642\n",
      "Epoch 24/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 12.8505\n",
      "Epoch 25/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 12.6711\n",
      "Epoch 26/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 12.7925\n",
      "Epoch 27/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 12.6966\n",
      "Epoch 28/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 12.1073\n",
      "Epoch 29/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 12.0382\n",
      "Epoch 30/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 11.9698\n",
      "Epoch 31/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 11.9071\n",
      "Epoch 32/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 11.8191\n",
      "Epoch 33/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 11.4379\n",
      "Epoch 34/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 11.2994\n",
      "Epoch 35/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 11.0315\n",
      "Epoch 36/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 10.9106\n",
      "Epoch 37/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 11.0249\n",
      "Epoch 38/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 10.5841\n",
      "Epoch 39/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 10.5087\n",
      "Epoch 40/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 10.7455\n",
      "Epoch 41/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 10.3063\n",
      "Epoch 42/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 10.1652\n",
      "Epoch 43/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 9.8668\n",
      "Epoch 44/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 9.8656\n",
      "Epoch 45/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 9.7147\n",
      "Epoch 46/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 9.5925\n",
      "Epoch 47/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 9.3117\n",
      "Epoch 48/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 9.1075\n",
      "Epoch 49/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 8.9772\n",
      "Epoch 50/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 8.9177\n",
      "Epoch 51/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 9.3249\n",
      "Epoch 52/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 8.5692\n",
      "Epoch 53/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 8.4538\n",
      "Epoch 54/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 8.5647\n",
      "Epoch 55/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 8.1070\n",
      "Epoch 56/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 7.9950\n",
      "Epoch 57/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 7.8781\n",
      "Epoch 58/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 7.7531\n",
      "Epoch 59/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 8.0473\n",
      "Epoch 60/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 7.9406\n",
      "Epoch 61/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 7.4945\n",
      "Epoch 62/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 7.4671\n",
      "Epoch 63/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 7.5052\n",
      "Epoch 64/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 7.0449\n",
      "Epoch 65/250\n",
      "70/70 [==============================] - 0s 257us/sample - loss: 7.0324\n",
      "Epoch 66/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 7.0214\n",
      "Epoch 67/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 6.9713\n",
      "Epoch 68/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 6.8716\n",
      "Epoch 69/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 6.5063\n",
      "Epoch 70/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 6.3560\n",
      "Epoch 71/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 6.4009\n",
      "Epoch 72/250\n",
      "70/70 [==============================] - 0s 129us/sample - loss: 6.1968\n",
      "Epoch 73/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 6.2866\n",
      "Epoch 74/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 5.9076\n",
      "Epoch 75/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 5.9349\n",
      "Epoch 76/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.914 - 0s 157us/sample - loss: 5.8050\n",
      "Epoch 77/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 5.7834\n",
      "Epoch 78/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 5.5506\n",
      "Epoch 79/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 5.3408\n",
      "Epoch 80/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 5.2625\n",
      "Epoch 81/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 5.2043\n",
      "Epoch 82/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 5.1461\n",
      "Epoch 83/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 4.9205\n",
      "Epoch 84/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 4.8083\n",
      "Epoch 85/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 4.7498\n",
      "Epoch 86/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 4.5972\n",
      "Epoch 87/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 5.0076\n",
      "Epoch 88/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 4.3932\n",
      "Epoch 89/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 4.3169\n",
      "Epoch 90/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 4.2837\n",
      "Epoch 91/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 4.4081\n",
      "Epoch 92/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 4.0396\n",
      "Epoch 93/250\n",
      "70/70 [==============================] - 0s 243us/sample - loss: 4.1622\n",
      "Epoch 94/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 3.9137\n",
      "Epoch 95/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 3.7468\n",
      "Epoch 96/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 157us/sample - loss: 3.6809\n",
      "Epoch 97/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 3.6286\n",
      "Epoch 98/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 3.8453\n",
      "Epoch 99/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 3.4349\n",
      "Epoch 100/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 3.3691\n",
      "Epoch 101/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 3.2838\n",
      "Epoch 102/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 3.3050\n",
      "Epoch 103/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 3.4114\n",
      "Epoch 104/250\n",
      "70/70 [==============================] - 0s 243us/sample - loss: 3.3223\n",
      "Epoch 105/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 3.0147\n",
      "Epoch 106/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 2.9916\n",
      "Epoch 107/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 2.8369\n",
      "Epoch 108/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 2.8687\n",
      "Epoch 109/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 2.7123\n",
      "Epoch 110/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 2.8441\n",
      "Epoch 111/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 2.5515\n",
      "Epoch 112/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 2.5268\n",
      "Epoch 113/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 2.5047\n",
      "Epoch 114/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 2.3758\n",
      "Epoch 115/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 2.2774\n",
      "Epoch 116/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 2.2216\n",
      "Epoch 117/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 2.1137\n",
      "Epoch 118/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 2.3529\n",
      "Epoch 119/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 2.0833\n",
      "Epoch 120/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 2.0416\n",
      "Epoch 121/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 1.8885\n",
      "Epoch 122/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 1.8173\n",
      "Epoch 123/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 1.9107\n",
      "Epoch 124/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.6727\n",
      "Epoch 125/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.6406\n",
      "Epoch 126/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 1.8134\n",
      "Epoch 127/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.947 - 0s 214us/sample - loss: 1.5251\n",
      "Epoch 128/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 1.5139\n",
      "Epoch 129/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.836 - 0s 200us/sample - loss: 1.5319\n",
      "Epoch 130/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.4284\n",
      "Epoch 131/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 1.5367\n",
      "Epoch 132/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 1.2581\n",
      "Epoch 133/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.4457\n",
      "Epoch 134/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 1.1844\n",
      "Epoch 135/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.1746\n",
      "Epoch 136/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.1108\n",
      "Epoch 137/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.0956\n",
      "Epoch 138/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 1.0144\n",
      "Epoch 139/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 1.1106\n",
      "Epoch 140/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 1.0306\n",
      "Epoch 141/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 1.0191\n",
      "Epoch 142/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.8882\n",
      "Epoch 143/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 0.8163\n",
      "Epoch 144/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.8569\n",
      "Epoch 145/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.7419\n",
      "Epoch 146/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.6913\n",
      "Epoch 147/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.7867\n",
      "Epoch 148/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.7138\n",
      "Epoch 149/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.6396\n",
      "Epoch 150/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.7592\n",
      "Epoch 151/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.5843\n",
      "Epoch 152/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.5973\n",
      "Epoch 153/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.6773\n",
      "Epoch 154/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.4826\n",
      "Epoch 155/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 0.4615\n",
      "Epoch 156/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.4485\n",
      "Epoch 157/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.4309\n",
      "Epoch 158/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.3854\n",
      "Epoch 159/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.3796\n",
      "Epoch 160/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 0.3913\n",
      "Epoch 161/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.3065\n",
      "Epoch 162/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 0.3332\n",
      "Epoch 163/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.3054\n",
      "Epoch 164/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.3923\n",
      "Epoch 165/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.2766\n",
      "Epoch 166/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.2469\n",
      "Epoch 167/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.3189\n",
      "Epoch 168/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.2068\n",
      "Epoch 169/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.1850\n",
      "Epoch 170/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.1871\n",
      "Epoch 171/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.2098\n",
      "Epoch 172/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.2544\n",
      "Epoch 173/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.1899\n",
      "Epoch 174/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.1318\n",
      "Epoch 175/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.1150\n",
      "Epoch 176/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.3013\n",
      "Epoch 177/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.1035\n",
      "Epoch 178/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.2034\n",
      "Epoch 179/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.1246\n",
      "Epoch 180/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0974\n",
      "Epoch 181/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.1066\n",
      "Epoch 182/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0990\n",
      "Epoch 183/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0885\n",
      "Epoch 184/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.1851\n",
      "Epoch 185/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 0.1377\n",
      "Epoch 186/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 0.0526\n",
      "Epoch 187/250\n",
      "70/70 [==============================] - 0s 143us/sample - loss: 0.0543\n",
      "Epoch 188/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0922\n",
      "Epoch 189/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0834\n",
      "Epoch 190/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.103 - 0s 186us/sample - loss: 0.0805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 191/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.1110\n",
      "Epoch 192/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0669\n",
      "Epoch 193/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0558\n",
      "Epoch 194/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0325\n",
      "Epoch 195/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0584\n",
      "Epoch 196/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 0.1323\n",
      "Epoch 197/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0722\n",
      "Epoch 198/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0255\n",
      "Epoch 199/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0454\n",
      "Epoch 200/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0455\n",
      "Epoch 201/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0756\n",
      "Epoch 202/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0474\n",
      "Epoch 203/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0131\n",
      "Epoch 204/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0286\n",
      "Epoch 205/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.1097\n",
      "Epoch 206/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0653\n",
      "Epoch 207/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0365\n",
      "Epoch 208/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0172\n",
      "Epoch 209/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0379\n",
      "Epoch 210/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0853\n",
      "Epoch 211/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0349\n",
      "Epoch 212/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0233\n",
      "Epoch 213/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0834\n",
      "Epoch 214/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0418\n",
      "Epoch 215/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0629\n",
      "Epoch 216/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0512\n",
      "Epoch 217/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 0.0135\n",
      "Epoch 218/250\n",
      "70/70 [==============================] - 0s 328us/sample - loss: 0.0148\n",
      "Epoch 219/250\n",
      "70/70 [==============================] - 0s 371us/sample - loss: 0.0330\n",
      "Epoch 220/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0930\n",
      "Epoch 221/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0410\n",
      "Epoch 222/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0206\n",
      "Epoch 223/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0487\n",
      "Epoch 224/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0688\n",
      "Epoch 225/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0328\n",
      "Epoch 226/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0153\n",
      "Epoch 227/250\n",
      "70/70 [==============================] - 0s 357us/sample - loss: 0.0271\n",
      "Epoch 228/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0782\n",
      "Epoch 229/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0526\n",
      "Epoch 230/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0197\n",
      "Epoch 231/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0143\n",
      "Epoch 232/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0384\n",
      "Epoch 233/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0778\n",
      "Epoch 234/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0714\n",
      "Epoch 235/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0052\n",
      "Epoch 236/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 0.0072\n",
      "Epoch 237/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0688\n",
      "Epoch 238/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0436\n",
      "Epoch 239/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0305\n",
      "Epoch 240/250\n",
      "70/70 [==============================] - 0s 200us/sample - loss: 0.0370\n",
      "Epoch 241/250\n",
      "70/70 [==============================] - 0s 214us/sample - loss: 0.0751\n",
      "Epoch 242/250\n",
      "70/70 [==============================] - 0s 157us/sample - loss: 0.0352\n",
      "Epoch 243/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0148\n",
      "Epoch 244/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0366\n",
      "Epoch 245/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0687\n",
      "Epoch 246/250\n",
      "70/70 [==============================] - 0s 186us/sample - loss: 0.0354\n",
      "Epoch 247/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0158\n",
      "Epoch 248/250\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.026 - 0s 186us/sample - loss: 0.0312\n",
      "Epoch 249/250\n",
      "70/70 [==============================] - 0s 228us/sample - loss: 0.0689\n",
      "Epoch 250/250\n",
      "70/70 [==============================] - 0s 171us/sample - loss: 0.0364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa403d1488>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, epochs = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 0s 100us/sample - loss: 0.0389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03891986235976219"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 128us/sample - loss: 0.0387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.038716745270150045"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = pd.Series(test_prediction.reshape(30,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     87.346992\n",
       "1     64.056259\n",
       "2     73.617874\n",
       "3     79.384567\n",
       "4     68.396713\n",
       "5     68.804947\n",
       "6     64.622299\n",
       "7     69.390755\n",
       "8     61.223206\n",
       "9     66.619865\n",
       "10    62.839806\n",
       "11    72.023041\n",
       "12    67.825020\n",
       "13    73.805061\n",
       "14    68.805099\n",
       "15    76.157478\n",
       "16    72.571785\n",
       "17    67.572166\n",
       "18    71.415886\n",
       "19    53.454945\n",
       "20    58.472958\n",
       "21    87.550636\n",
       "22    71.584877\n",
       "23    81.958069\n",
       "24    74.587318\n",
       "25    73.426712\n",
       "26    61.064304\n",
       "27    78.780243\n",
       "28    75.387268\n",
       "29    70.817741\n",
       "dtype: float32"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.DataFrame(y_test, columns = ['True Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>64.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>73.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>79.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>61.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>66.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>72.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>87.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>82.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>74.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>73.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>61.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>75.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    True Value\n",
       "0         87.6\n",
       "1         64.2\n",
       "2         73.8\n",
       "3         79.6\n",
       "4         68.6\n",
       "5         69.0\n",
       "6         64.8\n",
       "7         69.6\n",
       "8         61.4\n",
       "9         66.8\n",
       "10        63.0\n",
       "11        72.2\n",
       "12        68.0\n",
       "13        74.0\n",
       "14        69.0\n",
       "15        76.4\n",
       "16        72.8\n",
       "17        67.8\n",
       "18        71.6\n",
       "19        53.6\n",
       "20        58.6\n",
       "21        87.8\n",
       "22        71.8\n",
       "23        82.2\n",
       "24        74.8\n",
       "25        73.6\n",
       "26        61.2\n",
       "27        79.0\n",
       "28        75.6\n",
       "29        71.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = pd.concat([pre_df, test_prediction], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Value</th>\n",
       "      <th>Predicted Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87.6</td>\n",
       "      <td>87.346992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>64.2</td>\n",
       "      <td>64.056259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>73.8</td>\n",
       "      <td>73.617874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>79.6</td>\n",
       "      <td>79.384567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68.6</td>\n",
       "      <td>68.396713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>68.804947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>64.8</td>\n",
       "      <td>64.622299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>69.6</td>\n",
       "      <td>69.390755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>61.4</td>\n",
       "      <td>61.223206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>66.8</td>\n",
       "      <td>66.619865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>63.0</td>\n",
       "      <td>62.839806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>72.2</td>\n",
       "      <td>72.023041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.825020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>74.0</td>\n",
       "      <td>73.805061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>69.0</td>\n",
       "      <td>68.805099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>76.4</td>\n",
       "      <td>76.157478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>72.8</td>\n",
       "      <td>72.571785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>67.8</td>\n",
       "      <td>67.572166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>71.6</td>\n",
       "      <td>71.415886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.454945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>58.6</td>\n",
       "      <td>58.472958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>87.8</td>\n",
       "      <td>87.550636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>71.8</td>\n",
       "      <td>71.584877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>82.2</td>\n",
       "      <td>81.958069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>74.8</td>\n",
       "      <td>74.587318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>73.6</td>\n",
       "      <td>73.426712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>61.2</td>\n",
       "      <td>61.064304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>79.0</td>\n",
       "      <td>78.780243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>75.6</td>\n",
       "      <td>75.387268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.817741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    True Value  Predicted Value\n",
       "0         87.6        87.346992\n",
       "1         64.2        64.056259\n",
       "2         73.8        73.617874\n",
       "3         79.6        79.384567\n",
       "4         68.6        68.396713\n",
       "5         69.0        68.804947\n",
       "6         64.8        64.622299\n",
       "7         69.6        69.390755\n",
       "8         61.4        61.223206\n",
       "9         66.8        66.619865\n",
       "10        63.0        62.839806\n",
       "11        72.2        72.023041\n",
       "12        68.0        67.825020\n",
       "13        74.0        73.805061\n",
       "14        69.0        68.805099\n",
       "15        76.4        76.157478\n",
       "16        72.8        72.571785\n",
       "17        67.8        67.572166\n",
       "18        71.6        71.415886\n",
       "19        53.6        53.454945\n",
       "20        58.6        58.472958\n",
       "21        87.8        87.550636\n",
       "22        71.8        71.584877\n",
       "23        82.2        81.958069\n",
       "24        74.8        74.587318\n",
       "25        73.6        73.426712\n",
       "26        61.2        61.064304\n",
       "27        79.0        78.780243\n",
       "28        75.6        75.387268\n",
       "29        71.0        70.817741"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.columns = (['True Value', 'Predicted Value'])\n",
    "pre_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
